{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f5c3b49-2cb9-455a-a6af-c176a1091ec4",
   "metadata": {},
   "source": [
    "## Do you see what I see? Using PyTorch Deep Learning Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2615f581-a7a8-4ec3-9437-b71607c0199d",
   "metadata": {},
   "source": [
    "In this short project I will start diving into Deep Learning pretrained models for object detection and image classification. I will use mainly PyTorch, but I will bring MATLAB and Simulink for augmented capabilities when exploring ways to improve the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f0c4b59-ae40-4a21-820d-7cc24d7b8f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2  #pip install opencv-python\n",
    "from PIL import Image, ImageDraw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4f1ed7-081c-43cb-8a36-1d55735258d4",
   "metadata": {},
   "source": [
    "### 1) Load an image and display it\n",
    "Let's start with a very simple image on a street that includes several objects. Let's display the image first: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1179d76a-f184-4340-a312-1ca2b6c24f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load an image with OpenCV\n",
    "cv2_image = cv2.imread(\"image_street.jpg\")\n",
    "\n",
    "# Convert the image to grayscale\n",
    "grayscale_image = cv2.cvtColor(cv2_image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Resize the image\n",
    "resized_image = cv2.resize(grayscale_image, (224, 224))\n",
    "\n",
    "# Convert back to RGB for display\n",
    "resized_image = cv2.cvtColor(resized_image, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "# Display the processed image using PIL\n",
    "processed_image = Image.fromarray(resized_image)\n",
    "processed_image.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c465d1-1372-422a-8fca-ce526d18f5c2",
   "metadata": {},
   "source": [
    "### 2) Use a pretrained PyTorch model to detect and classify objects in the image\n",
    "I'd like to use first a pretrained model to detect and label all the objects in the image. I've heard of Mask-R-CNN ResNet 50 as an architecture that can help me with this: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fecf591e-6f24-411e-8a96-2009bb003d21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\WPy64-39100\\python-3.9.10.amd64\\lib\\site-packages\\torch\\functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ..\\aten\\src\\ATen\\native\\TensorShape.cpp:2157.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import models, transforms\n",
    "\n",
    "# Load the pre-trained Mask R-CNN model\n",
    "model = models.detection.maskrcnn_resnet50_fpn(pretrained=True)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "# Image transformation\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Load the processed image\n",
    "image_tensor = transform(processed_image).unsqueeze(0)\n",
    "\n",
    "# Perform inference\n",
    "with torch.no_grad():\n",
    "    predictions = model(image_tensor)\n",
    "\n",
    "# Draw bounding boxes\n",
    "draw = ImageDraw.Draw(processed_image)\n",
    "for element in predictions[0]['boxes']:\n",
    "    draw.rectangle([(element[0], element[1]), (element[2], element[3])], outline=\"red\", width=3)\n",
    "\n",
    "# Show the image with bounding boxes\n",
    "processed_image.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef73be1-7b7f-4184-bf9c-f7e54cc292ba",
   "metadata": {},
   "source": [
    "### 3) Use a pretrained image classification model so we obtain one label for the image\n",
    "In my previous test I realized that I'm not looking to do detection, but rather image classification. This will be faster and I'll obtain just one prediction per image. I'll test ResNet 50, and trace the model so it will be optimized using just-in-time compilation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "633845a8-e0dd-4bbc-afbb-e5146f52ea46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Class: traffic light\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "import requests\n",
    "\n",
    "# Load the pre-trained ResNet50 model\n",
    "model = models.resnet50(pretrained=True)\n",
    "model.eval()\n",
    "\n",
    "# Define image transformation: resize, center crop, normalize, and convert to tensor\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "       mean=[0.485, 0.456, 0.406],\n",
    "       std=[0.229, 0.224, 0.225]\n",
    "    ),\n",
    "])\n",
    "\n",
    "# Load the image (local file or URL)\n",
    "image_path = \"image_street.jpg\" \n",
    "image = Image.open(image_path)\n",
    "\n",
    "# Apply the transformations to the image\n",
    "image_tensor = transform(image).unsqueeze(0) # Add batch dimension\n",
    "\n",
    "# Perform inference with the model\n",
    "with torch.no_grad():\n",
    "    outputs = model(image_tensor)\n",
    "\n",
    "# Get the predicted class index\n",
    "_, predicted_idx = outputs.max(1)\n",
    "\n",
    "# Load ImageNet labels (if you don't have a local file, you can use an online resource)\n",
    "LABELS_URL = \"https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt\"\n",
    "labels = requests.get(LABELS_URL).text.splitlines()\n",
    "\n",
    "# Print the top predicted label\n",
    "predicted_label = labels[predicted_idx.item()]\n",
    "print(f\"Predicted Class: {predicted_label}\")\n",
    "\n",
    "# Create a temp tensor for tracing\n",
    "temp_input = torch.randn(1,3,224,224)\n",
    "#Trace the model\n",
    "traced_model = torch.jit.trace(model,temp_input)\n",
    "\n",
    "traced_model.save(\"resnet50_traced.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ad54d1-75a2-4333-a681-f54eeed36646",
   "metadata": {},
   "source": [
    "### 4) Let's bring MATLAB for additional exploration and capabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e040ac3-1448-4efc-86b8-5f967186e5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matlab.engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae66bef5-188c-4ba3-880c-683f9d8e6cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the MATLAB Engine session that you can use to connect\n",
    "\n",
    "eng = matlab.engine.start_matlab('-desktop')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66428cab-a700-43d6-8e19-1d87e97456fd",
   "metadata": {},
   "source": [
    "As a quick test of the engine, let's determine the greatest common denominator of two numbers, use the gcd function. Set nargout to return the three output arguments from gcd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d6ae24e-469a-49a2-9393-cc3544b6346b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20.0, 1.0, -1.0)\n"
     ]
    }
   ],
   "source": [
    "t = eng.gcd(100.0,80.0,nargout=3)\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316bdcc4-846a-453d-a77f-01b30c084108",
   "metadata": {},
   "source": [
    "I can also open the documentation from here at any point:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd6ea86d-f382-4d41-a1c9-b1d254ed981e",
   "metadata": {},
   "outputs": [],
   "source": [
    "eng.doc(nargout=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77fc67a4-f9e0-4ff0-b687-cc94c745f0ce",
   "metadata": {},
   "source": [
    "I can also call apps and tools from the MATLAB ecosystem. For example, let's take a look at the Deep Network Designer to examine the architecture of the ResNet 50 traced model I saved earlier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1836d7-fa2c-464c-b027-d53b5bf56ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "eng.deepNetworkDesigner(nargout=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228b2385-4301-41ef-8a95-dfacc674eafc",
   "metadata": {},
   "source": [
    "I can also access the MATLAB workspace and manipulate variables from my Python code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080c4721-4d6a-4a06-9b8c-ac98f34cf750",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "image = Image.open(\"image_street.jpg\")\n",
    "eng.workspace[\"image_array\"] = np.array(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d893b9a-451b-4502-94be-005dd64ade8d",
   "metadata": {},
   "source": [
    "Now, rather than converting the PyTorch model, I'd like to test a model directly in Simulink. First, let's load the model I want to use, for instance the MNASNet model which has been optimized to balance between accuracy and latency:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ca8be8-360b-427c-9f1b-7454a2a415ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained mnasnet model\n",
    "model = models.mnasnet1_0(pretrained=True)\n",
    "\n",
    "# Original model\n",
    "torch.save(model,'mnasnet1_0.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57519481-dfeb-4d00-a3dd-d515267ba735",
   "metadata": {},
   "source": [
    "I could start with an empty Simulink model, or I could use the documentation example I just saw, and edit it as needed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5657ee3-abb5-47c1-9509-eaa67794404b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "cwd = os.getcwd()\n",
    "eng.openExample(\"deeplearning_shared/ClassifyImagesPyTorchModelPredictBlockExample\",\"workDir\",cwd,nargout=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd825d5-14ab-4079-b135-4fb2346dc989",
   "metadata": {},
   "source": [
    "Call either the exit or the quit function to stop the MATLAB engine. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d1fdfd-5f11-45b1-aecc-db4edfa846c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "eng.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78405c2e-4640-4dde-a1f9-99623fd7e318",
   "metadata": {},
   "source": [
    "This is just the start. Once I'm more familiar with transfer learning to expand the use of the pretrained models, I could use other sources of data for model training."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
